{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b005e4cc",
   "metadata": {},
   "source": [
    "## TUT1-Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01c6792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.backends.mps.is_available()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b23ea",
   "metadata": {},
   "source": [
    "### 1. Load & split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fe4a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from datasets import load_dataset           \n",
    "imdb = load_dataset(\"imdb\")                       # IMDB（train/test）\n",
    "ag   = load_dataset(\"ag_news\")                    # AG_NEWS（train/test）\n",
    "# print(imdb)   \n",
    "# print(ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5ac1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set: train, validation(10%), test\n",
    "# IMDB\n",
    "imdb_split = imdb[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "imdb_train = imdb_split[\"train\"]\n",
    "imdb_val   = imdb_split[\"test\"]   \n",
    "imdb_test  = imdb[\"test\"]\n",
    "\n",
    "# AG_NEWS\n",
    "ag_split = ag[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "ag_train = ag_split[\"train\"]\n",
    "ag_val   = ag_split[\"test\"]\n",
    "ag_test  = ag[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e941896a",
   "metadata": {},
   "source": [
    "### 2. Vocab & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85c871a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize: \"I'm loving it in 2024!!!\" -> [\"i'm\", \"loving\", \"it\", \"in\", \"2024\"]\n",
    "import re\n",
    "\n",
    "TOKEN_RE = re.compile(r\"[A-Za-z]+(?:'[A-Za-z]+)*|[0-9]+\")  #t least one letter + “'” + number0-9\n",
    "\n",
    "def tokenize(text: str, lowercase: bool = True):\n",
    "    if lowercase:\n",
    "        text = text.lower()       # Apple=apple\n",
    "    return TOKEN_RE.findall(text)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eff1c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocab\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "PAD_TOKEN = '<pad>' \n",
    "UNK_TOKEN = '<unk>'\n",
    "\n",
    "def build_vocab(\n",
    "    dataset,\n",
    "    text_key: str = \"text\",\n",
    "    max_vocab: int = 30000,\n",
    "    min_freq: int = 2,\n",
    "    add_bos_eos: bool = False,\n",
    ") -> Tuple[Dict[str, int], List[str]]:\n",
    "    \"\"\"\n",
    "    从（通常是 train split 的）dataset 构建词表。\n",
    "    仅使用训练集统计，避免验证/测试信息泄漏。\n",
    "\n",
    "    参数：\n",
    "        dataset   : HuggingFace Dataset（建议传 train split）\n",
    "        text_key  : 文本字段名（IMDB/AG_NEWS 都是 'text'）\n",
    "        max_vocab : 词表上限（含特殊符号）；控制模型尺寸与稀疏\n",
    "        min_freq  : 最小词频；低于此阈值的词丢弃为 <unk>\n",
    "        add_bos_eos: 是否在序列首尾加入 <bos>/<eos>（分类任务一般 False）\n",
    "\n",
    "    返回：\n",
    "        token2id  : dict，token -> id 映射（含 <pad>=0, <unk>=1, 以及可选 <bos>/<eos>）\n",
    "        id2token  : list，下标即 id，元素为对应 token（便于调试/反查）\n",
    "    \"\"\"\n",
    "    counter = Counter()  # 计数器：高效累加词频\n",
    "\n",
    "    # 1) 统计词频（只遍历训练集，避免泄漏）\n",
    "    for ex in dataset:\n",
    "        tokens = tokenize(ex[text_key])\n",
    "        if add_bos_eos:\n",
    "            tokens = [\"<bos>\", *tokens, \"<eos>\"]\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # 2) 初始化特殊符号，固定在最前面的 id（便于 padding/UNK 处理）\n",
    "    specials = [PAD, UNK] + ([\"<bos>\", \"<eos>\"] if add_bos_eos else [])\n",
    "    token2id: Dict[str, int] = {tok: i for i, tok in enumerate(specials)}\n",
    "\n",
    "    # 3) 按频次从高到低加入普通 token，受 min_freq / max_vocab 约束\n",
    "    for tok, freq in counter.most_common():\n",
    "        if freq < min_freq:\n",
    "            break                 # 后续频次更低，提前结束\n",
    "        if tok in token2id:\n",
    "            continue              # 跳过已在 specials 的符号\n",
    "        if len(token2id) >= max_vocab:\n",
    "            break\n",
    "        token2id[tok] = len(token2id)\n",
    "\n",
    "    # 4) 反向表：id -> token，便于可视化/调试\n",
    "    id2token: List[str] = [None] * len(token2id)\n",
    "    for tok, idx in token2id.items():\n",
    "        id2token[idx] = tok\n",
    "\n",
    "    return token2id, id2token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61b0ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode function\n",
    "def encode(\n",
    "    text: str,\n",
    "    token2id: dict,\n",
    "    max_len: int = 256,\n",
    "    add_bos_eos: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    把一条文本转成 token id 序列。\n",
    "    \n",
    "    参数：\n",
    "        text        : 输入的一条文本\n",
    "        token2id    : 词表 (token -> id 映射)\n",
    "        max_len     : 截断的最大长度（避免太长耗内存）\n",
    "        add_bos_eos : 是否在开头/结尾加 <bos>/<eos>\n",
    "    \n",
    "    返回：\n",
    "        List[int]   : token id 序列（长度 <= max_len）\n",
    "    \"\"\"\n",
    "    # 1. 分词\n",
    "    tokens = tokenize(text)\n",
    "\n",
    "    # 2. 可选：加入 <bos> 和 <eos>\n",
    "    if add_bos_eos:\n",
    "        tokens = [\"<bos>\", *tokens, \"<eos>\"]\n",
    "\n",
    "    # 3. 把 token 转 id，不在 vocab 的词用 <unk>\n",
    "    unk_id = token2id.get(\"<unk>\")\n",
    "    ids = [token2id.get(tok, unk_id) for tok in tokens]\n",
    "\n",
    "    # 4. 截断到 max_len\n",
    "    ids = ids[:max_len]\n",
    "\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "495e7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding & Collate\n",
    "def collate_fn(batch, token2id, max_len=256):\n",
    "    \"\"\"\n",
    "    把一个 batch 的样本整理成可训练的张量。\n",
    "    \n",
    "    参数：\n",
    "        batch    : List[Dict]，HuggingFace dataset 里的一批数据\n",
    "        token2id : 词表\n",
    "        max_len  : 截断长度\n",
    "    \n",
    "    返回：\n",
    "        padded   : LongTensor [B, T]  (已pad的id序列)\n",
    "        lengths  : LongTensor [B]     (每个序列的真实长度)\n",
    "        labels   : LongTensor [B]     (分类任务的标签)\n",
    "    \"\"\"\n",
    "    PAD_ID = token2id[\"<pad>\"]\n",
    "    unk_id = token2id[\"<unk>\"]\n",
    "\n",
    "    # 1. 逐条 encode\n",
    "    encoded = [encode(ex[\"text\"], token2id, max_len=max_len) for ex in batch]\n",
    "    lengths = [len(seq) for seq in encoded]\n",
    "    maxL = max(lengths) if lengths else 1   # 本 batch 的最大长度\n",
    "\n",
    "    # 2. padding\n",
    "    padded = [seq + [PAD_ID]*(maxL - len(seq)) for seq in encoded]\n",
    "\n",
    "    # 3. 提取 labels\n",
    "    labels = [ex[\"label\"] for ex in batch]\n",
    "\n",
    "    # 4. 转成 PyTorch Tensor\n",
    "    padded = torch.tensor(padded, dtype=torch.long)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return padded, lengths, labels\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "def make_loader(ds, token2id, batch_size=64, max_len=256, shuffle=True):\n",
    "    return DataLoader(\n",
    "        ds, batch_size=batch_size, shuffle=shuffle,\n",
    "        collate_fn=partial(collate_fn, token2id=token2id, max_len=max_len)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3365d48",
   "metadata": {},
   "source": [
    "### 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2651e",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dad0fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    一个最小可用的 RNN 文本分类器：\n",
    "    Embedding -> RNN -> 取最后层隐藏状态 -> Dropout -> 全连接分类头\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,      # 词表大小（len(token2id)）\n",
    "        num_labels: int,      # 类别数（IMDB=2, AG_NEWS=4）\n",
    "        pad_id: int = 0,      # <pad> 的 id（我们约定为0）\n",
    "        emb_dim: int = 128,   # 词向量维度（超参）\n",
    "        hidden_dim: int = 256,# RNN 隐层维度（超参）\n",
    "        num_layers: int = 1,  # RNN 层数（>1可加深）\n",
    "        bidirectional: bool = True,  # 是否双向RNN（一般建议True）\n",
    "        dropout: float = 0.2  # Dropout 概率\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # 1) 嵌入层：把 token id 映射成向量\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim,\n",
    "            padding_idx=pad_id     # <pad>行会被固定为全0，且RNN计算时可被“忽略”\n",
    "        )\n",
    "\n",
    "        # 2) RNN 编码器：batch_first=True -> 输入/输出形状都是 [B, T, *]\n",
    "        # 注意：nn.RNN 的 dropout 参数只有在 num_layers > 1 时才会生效\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        # 3) 分类头\n",
    "        out_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(out_dim, num_labels)\n",
    "\n",
    "        # 额外保存一些属性（非必须，调试友好）\n",
    "        self.pad_id = pad_id\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        x:       LongTensor [B, T]  —— padded 的 token id 序列（来自 collate_fn）\n",
    "        lengths: LongTensor [B]     —— 每个序列的真实长度（来自 collate_fn）\n",
    "\n",
    "        返回：\n",
    "        logits:  FloatTensor [B, num_labels]\n",
    "        \"\"\"\n",
    "        # 1) id -> 向量序列\n",
    "        emb = self.embedding(x)  # [B, T, E]\n",
    "\n",
    "        # 2) 为了让 RNN 忽略 padding，使用 pack_padded_sequence\n",
    "        #    enforce_sorted=False：允许 lengths 无序（我们一般不会预排序）\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # 3) 过 RNN\n",
    "        #    输出 h_n 形状：[num_layers * num_directions, B, hidden_dim]\n",
    "        packed_out, h_n = self.rnn(packed)\n",
    "\n",
    "        # 4) 取“最后一层”的最终隐藏状态作为句向量\n",
    "        #    单向：        h_n[-1]         -> [B, H]\n",
    "        #    双向：拼接最后一层的正向/反向 -> [B, 2H]\n",
    "        if self.bidirectional:\n",
    "            # 最后一层的两个方向在 h_n 的最后两个切片\n",
    "            # 形状：[num_layers*2, B, H] -> 取[-2]正向、[-1]反向，再在特征维拼接\n",
    "            last = torch.cat([h_n[-2], h_n[-1]], dim=1)  # [B, 2H]\n",
    "        else:\n",
    "            last = h_n[-1]  # [B, H]\n",
    "\n",
    "        # 5) Dropout + 全连接分类头（输出未归一化的 logits）\n",
    "        out = self.dropout(last)      # [B, out_dim]\n",
    "        logits = self.fc(out)         # [B, num_labels]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7486a",
   "metadata": {},
   "source": [
    "#### LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25105a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Embedding -> LSTM -> 取最后层的正/反向最后隐藏态 -> Dropout -> 全连接\n",
    "    用法/输入与 RNNClassifier 保持一致。\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        num_labels: int,\n",
    "        pad_id: int = 0,\n",
    "        emb_dim: int = 128,\n",
    "        hidden_dim: int = 256,\n",
    "        num_layers: int = 1,\n",
    "        bidirectional: bool = True,\n",
    "        dropout: float = 0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        out_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(out_dim, num_labels)\n",
    "        self.pad_id = pad_id\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        x: [B, T]  padded token ids\n",
    "        lengths: [B]  每条样本的真实长度\n",
    "        return: logits [B, num_labels]\n",
    "        \"\"\"\n",
    "        emb = self.embedding(x)  # [B, T, E]\n",
    "\n",
    "        # pack 让 LSTM 忽略 padding\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_out, (h_n, c_n) = self.lstm(packed)\n",
    "        # h_n: [num_layers * num_directions, B, H]\n",
    "\n",
    "        if self.bidirectional:\n",
    "            sent_vec = torch.cat([h_n[-2], h_n[-1]], dim=1)  # [B, 2H]\n",
    "        else:\n",
    "            sent_vec = h_n[-1]  # [B, H]\n",
    "\n",
    "        logits = self.fc(self.dropout(sent_vec))  # [B, num_labels]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18aba5",
   "metadata": {},
   "source": [
    "#### Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9f81b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerEncoderClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_labels, pad_id,\n",
    "                 emb_dim=128, nhead=4, num_layers=2,\n",
    "                 dim_feedforward=512, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "        self.pos_emb = nn.Embedding(max_len, emb_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(emb_dim, num_labels)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: [batch, seq_len]\n",
    "        batch, seq_len = x.size()\n",
    "        pos = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch, seq_len)\n",
    "        out = self.emb(x) + self.pos_emb(pos)  # [batch, seq_len, emb_dim]\n",
    "        out = self.encoder(out)                # [batch, seq_len, emb_dim]\n",
    "        out = out.mean(dim=1)                  # 平均池化得到句子向量\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec047818",
   "metadata": {},
   "source": [
    "### 4. Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8065238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "# vocab\n",
    "imdb_token2id, imdb_id2token = build_vocab(imdb_train, max_vocab=30000, min_freq=2)\n",
    "ag_token2id,   ag_id2token   = build_vocab(ag_train,   max_vocab=30000, min_freq=2)\n",
    "PAD_IMDB = imdb_token2id[\"<pad>\"]\n",
    "PAD_AG   = ag_token2id[\"<pad>\"]\n",
    "\n",
    "# loader\n",
    "BATCH_SIZE   = 64\n",
    "MAX_LEN_IMDB = 256\n",
    "MAX_LEN_AG   = 128\n",
    "\n",
    "imdb_train_loader = make_loader(imdb_train, imdb_token2id, batch_size=BATCH_SIZE, max_len=MAX_LEN_IMDB, shuffle=True)\n",
    "imdb_val_loader   = make_loader(imdb_val,   imdb_token2id, batch_size=BATCH_SIZE, max_len=MAX_LEN_IMDB, shuffle=False)\n",
    "imdb_test_loader  = make_loader(imdb_test,  imdb_token2id, batch_size=BATCH_SIZE, max_len=MAX_LEN_IMDB, shuffle=False)\n",
    "\n",
    "ag_train_loader = make_loader(ag_train, ag_token2id, batch_size=BATCH_SIZE, max_len=MAX_LEN_AG, shuffle=True)\n",
    "ag_val_loader   = make_loader(ag_val,   ag_token2id, batch_size=BATCH_SIZE, max_len=MAX_LEN_AG, shuffle=False)\n",
    "ag_test_loader  = make_loader(ag_test,  ag_token2id, batch_size=BATCH_SIZE, max_len=MAX_LEN_AG, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228e3ae",
   "metadata": {},
   "source": [
    "#### Training/validation/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5717d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "EPOCHS = 3\n",
    "LR_RNN_LSTM = 2e-3\n",
    "LR_TRANS    = 1e-3\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, lr, save_name):\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        # train\n",
    "        model.train(); tl=tc=tn=0\n",
    "        for x,lens,y in train_loader:\n",
    "            x,lens,y = x.to(device), lens.to(device), y.to(device)\n",
    "            logits = model(x,lens); loss = loss_fn(logits,y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            bs = y.size(0); tl += loss.item()*bs; tc += (logits.argmax(1)==y).sum().item(); tn += bs\n",
    "\n",
    "        # val\n",
    "        model.eval(); vl=vc=vn=0\n",
    "        with torch.no_grad():\n",
    "            for x,lens,y in val_loader:\n",
    "                x,lens,y = x.to(device), lens.to(device), y.to(device)\n",
    "                logits = model(x,lens); loss = loss_fn(logits,y)\n",
    "                bs = y.size(0); vl += loss.item()*bs; vc += (logits.argmax(1)==y).sum().item(); vn += bs\n",
    "\n",
    "        print(f\"[{model.__class__.__name__}] Epoch {ep}: train {tl/tn:.4f}/{tc/tn:.4f} | val {vl/vn:.4f}/{vc/vn:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), save_name)\n",
    "    print(\"Saved:\", save_name)\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_and_report(model, test_loader, label_names=None):\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "    for x,lens,y in test_loader:\n",
    "        x,lens = x.to(device), lens.to(device)\n",
    "        pred = model(x,lens).argmax(1).cpu().tolist()\n",
    "        preds.extend(pred); gts.extend(y.tolist())\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(gts, preds))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(gts, preds, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef0349",
   "metadata": {},
   "source": [
    "#### IMDB：RNN → LSTM → Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2133e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RNNClassifier] Epoch 1: train 0.7239/0.5185 | val 0.7169/0.4928\n",
      "[RNNClassifier] Epoch 2: train 0.7252/0.5064 | val 0.7246/0.5160\n",
      "[RNNClassifier] Epoch 3: train 0.7180/0.5192 | val 0.7028/0.5348\n",
      "Saved: RNNClassifier_imdb.pth\n",
      "Confusion Matrix:\n",
      " [[6142 6358]\n",
      " [5789 6711]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.51      0.49      0.50     12500\n",
      "         pos       0.51      0.54      0.52     12500\n",
      "\n",
      "    accuracy                           0.51     25000\n",
      "   macro avg       0.51      0.51      0.51     25000\n",
      "weighted avg       0.51      0.51      0.51     25000\n",
      "\n",
      "[LSTMClassifier] Epoch 1: train 0.5998/0.6652 | val 0.5197/0.7388\n",
      "[LSTMClassifier] Epoch 2: train 0.4061/0.8115 | val 0.3445/0.8548\n",
      "[LSTMClassifier] Epoch 3: train 0.2377/0.9061 | val 0.3078/0.8692\n",
      "Saved: LSTMClassifier_imdb.pth\n",
      "Confusion Matrix:\n",
      " [[10981  1519]\n",
      " [ 2444 10056]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.88      0.85     12500\n",
      "         pos       0.87      0.80      0.84     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "[TransformerEncoderClassifier] Epoch 1: train 0.5025/0.7421 | val 0.3651/0.8372\n",
      "[TransformerEncoderClassifier] Epoch 2: train 0.3089/0.8698 | val 0.3216/0.8644\n",
      "[TransformerEncoderClassifier] Epoch 3: train 0.2188/0.9127 | val 0.3428/0.8604\n",
      "Saved: TransformerEncoderClassifier_imdb.pth\n",
      "Confusion Matrix:\n",
      " [[10949  1551]\n",
      " [ 2467 10033]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.88      0.84     12500\n",
      "         pos       0.87      0.80      0.83     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IMDB + RNN\n",
    "imdb_rnn = RNNClassifier(\n",
    "    vocab_size=len(imdb_token2id), num_labels=2, pad_id=PAD_IMDB,\n",
    "    emb_dim=128, hidden_dim=256, num_layers=1, bidirectional=True, dropout=0.2\n",
    ")\n",
    "imdb_rnn = train_and_validate(imdb_rnn, imdb_train_loader, imdb_val_loader, lr=LR_RNN_LSTM,\n",
    "                              save_name=\"RNNClassifier_imdb.pth\")\n",
    "test_and_report(imdb_rnn, imdb_test_loader, label_names=[\"neg\",\"pos\"])\n",
    "\n",
    "# IMDB + LSTM\n",
    "imdb_lstm = LSTMClassifier(\n",
    "    vocab_size=len(imdb_token2id), num_labels=2, pad_id=PAD_IMDB,\n",
    "    emb_dim=128, hidden_dim=256, num_layers=1, bidirectional=True, dropout=0.2\n",
    ")\n",
    "imdb_lstm = train_and_validate(imdb_lstm, imdb_train_loader, imdb_val_loader, lr=LR_RNN_LSTM,\n",
    "                               save_name=\"LSTMClassifier_imdb.pth\")\n",
    "test_and_report(imdb_lstm, imdb_test_loader, label_names=[\"neg\",\"pos\"])\n",
    "\n",
    "# IMDB + Transformer(Encoder-only)\n",
    "imdb_trans = TransformerEncoderClassifier(\n",
    "    vocab_size=len(imdb_token2id), num_labels=2, pad_id=PAD_IMDB,\n",
    "    emb_dim=128, nhead=4, num_layers=2, dim_feedforward=512, dropout=0.1, max_len=1024\n",
    ")\n",
    "imdb_trans = train_and_validate(imdb_trans, imdb_train_loader, imdb_val_loader, lr=LR_TRANS,\n",
    "                                save_name=\"TransformerEncoderClassifier_imdb.pth\")\n",
    "test_and_report(imdb_trans, imdb_test_loader, label_names=[\"neg\",\"pos\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fb4ed",
   "metadata": {},
   "source": [
    "#### AG_NEWS：RNN → LSTM → Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31d2de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RNNClassifier] Epoch 1: train 0.7775/0.7011 | val 0.7952/0.6930\n",
      "[RNNClassifier] Epoch 2: train 0.4563/0.8468 | val 0.3587/0.8858\n",
      "[RNNClassifier] Epoch 3: train 0.5065/0.8218 | val 0.7166/0.7636\n",
      "Saved: RNNClassifier_ag.pth\n",
      "Confusion Matrix:\n",
      " [[1482  217  123   78]\n",
      " [ 344 1503   27   26]\n",
      " [ 175   39 1486  200]\n",
      " [ 179   75  332 1314]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       World       0.68      0.78      0.73      1900\n",
      "      Sports       0.82      0.79      0.81      1900\n",
      "    Business       0.76      0.78      0.77      1900\n",
      "    Sci/Tech       0.81      0.69      0.75      1900\n",
      "\n",
      "    accuracy                           0.76      7600\n",
      "   macro avg       0.77      0.76      0.76      7600\n",
      "weighted avg       0.77      0.76      0.76      7600\n",
      "\n",
      "[LSTMClassifier] Epoch 1: train 0.4287/0.8478 | val 0.2889/0.9048\n",
      "[LSTMClassifier] Epoch 2: train 0.2126/0.9289 | val 0.2697/0.9119\n",
      "[LSTMClassifier] Epoch 3: train 0.1359/0.9533 | val 0.2610/0.9183\n",
      "Saved: LSTMClassifier_ag.pth\n",
      "Confusion Matrix:\n",
      " [[1726   48   76   50]\n",
      " [  18 1856   20    6]\n",
      " [  56   17 1663  164]\n",
      " [  56   23  112 1709]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       World       0.93      0.91      0.92      1900\n",
      "      Sports       0.95      0.98      0.97      1900\n",
      "    Business       0.89      0.88      0.88      1900\n",
      "    Sci/Tech       0.89      0.90      0.89      1900\n",
      "\n",
      "    accuracy                           0.92      7600\n",
      "   macro avg       0.91      0.92      0.91      7600\n",
      "weighted avg       0.91      0.92      0.91      7600\n",
      "\n",
      "[TransformerEncoderClassifier] Epoch 1: train 0.4838/0.8191 | val 0.3366/0.8831\n",
      "[TransformerEncoderClassifier] Epoch 2: train 0.2661/0.9111 | val 0.2886/0.9055\n",
      "[TransformerEncoderClassifier] Epoch 3: train 0.2088/0.9309 | val 0.2749/0.9090\n",
      "Saved: TransformerEncoderClassifier_ag.pth\n",
      "Confusion Matrix:\n",
      " [[1673   44  103   80]\n",
      " [  21 1829   30   20]\n",
      " [  44    9 1698  149]\n",
      " [  37    6  140 1717]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       World       0.94      0.88      0.91      1900\n",
      "      Sports       0.97      0.96      0.97      1900\n",
      "    Business       0.86      0.89      0.88      1900\n",
      "    Sci/Tech       0.87      0.90      0.89      1900\n",
      "\n",
      "    accuracy                           0.91      7600\n",
      "   macro avg       0.91      0.91      0.91      7600\n",
      "weighted avg       0.91      0.91      0.91      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label4 = [\"World\",\"Sports\",\"Business\",\"Sci/Tech\"]\n",
    "\n",
    "# AG + RNN\n",
    "ag_rnn = RNNClassifier(\n",
    "    vocab_size=len(ag_token2id), num_labels=4, pad_id=PAD_AG,\n",
    "    emb_dim=128, hidden_dim=256, num_layers=1, bidirectional=True, dropout=0.2\n",
    ")\n",
    "ag_rnn = train_and_validate(ag_rnn, ag_train_loader, ag_val_loader, lr=LR_RNN_LSTM,\n",
    "                            save_name=\"RNNClassifier_ag.pth\")\n",
    "test_and_report(ag_rnn, ag_test_loader, label_names=label4)\n",
    "\n",
    "# AG + LSTM\n",
    "ag_lstm = LSTMClassifier(\n",
    "    vocab_size=len(ag_token2id), num_labels=4, pad_id=PAD_AG,\n",
    "    emb_dim=128, hidden_dim=256, num_layers=1, bidirectional=True, dropout=0.2\n",
    ")\n",
    "ag_lstm = train_and_validate(ag_lstm, ag_train_loader, ag_val_loader, lr=LR_RNN_LSTM,\n",
    "                             save_name=\"LSTMClassifier_ag.pth\")\n",
    "test_and_report(ag_lstm, ag_test_loader, label_names=label4)\n",
    "\n",
    "# AG + Transformer(Encoder-only)\n",
    "ag_trans = TransformerEncoderClassifier(\n",
    "    vocab_size=len(ag_token2id), num_labels=4, pad_id=PAD_AG,\n",
    "    emb_dim=128, nhead=4, num_layers=2, dim_feedforward=512, dropout=0.1, max_len=512\n",
    ")\n",
    "ag_trans = train_and_validate(ag_trans, ag_train_loader, ag_val_loader, lr=LR_TRANS,\n",
    "                              save_name=\"TransformerEncoderClassifier_ag.pth\")\n",
    "test_and_report(ag_trans, ag_test_loader, label_names=label4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
